{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv1\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      2\u001b[0m tf\u001b[38;5;241m.\u001b[39mdisable_v2_behavior()\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclient\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m device_lib \n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(tf\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mlist_physical_devices())\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib \n",
    "print(tf.config.list_physical_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import librosa.display\n",
    "import IPython\n",
    "from IPython.display import Audio\n",
    "from IPython.display import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import torchaudio\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "EMOTIONS = {'Angry','Disgusted','Fearful','Happy','Neutral','Sad','Surprised'}\n",
    "DATA_PATH = 'C:\\\\Users\\\\Saransh\\\\Desktop\\\\Research Team\\\\data\\\\Combined\\\\Emotions\\\\'\n",
    "SAMPLE_RATE = 48000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(columns=['Emotion', 'Emotion intensity', 'Gender','Path'])\n",
    "for dirname, _, filenames in os.walk(DATA_PATH):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "        file_path = os.path.join('/kaggle/input/',dirname, filename)\n",
    "        identifiers = filename.split('.')[0].split('-')\n",
    "        data = data.append({\n",
    "                            \"Path\": file_path\n",
    "                             },\n",
    "                             ignore_index = True\n",
    "                          )\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"number of files is {}\".format(len(data)))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.bar(x=range(8), height=data['Emotion'].value_counts())\n",
    "ax.set_xticks(ticks=range(8))\n",
    "ax.set_xticklabels([EMOTIONS[i] for i in range(7)],fontsize=10)\n",
    "ax.set_xlabel('Emotion')\n",
    "ax.set_ylabel('Number of examples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mel_spectrograms = []\n",
    "signals = []\n",
    "for i, file_path in enumerate(data.Path):\n",
    "    audio, sample_rate = librosa.load(file_path, duration=3, offset=0.5, sr=SAMPLE_RATE)\n",
    "    signal = np.zeros((int(SAMPLE_RATE*3,)))\n",
    "    signal[:len(audio)] = audio\n",
    "    signals.append(signal)\n",
    "    print(\"\\r Processed {}/{} files\".format(i,len(data)),end='')\n",
    "signals = np.stack(signals,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMELspectrogram(audio, sample_rate):\n",
    "    mel_spec = librosa.feature.melspectrogram(y=audio,\n",
    "                                              sr=sample_rate,\n",
    "                                              n_fft=1024,\n",
    "                                              win_length = 512,\n",
    "                                              window='hamming',\n",
    "                                              hop_length = 256,\n",
    "                                              n_mels=128,\n",
    "                                              fmax=sample_rate/2\n",
    "                                             )\n",
    "    mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "    return mel_spec_db\n",
    "\n",
    "# test function\n",
    "audio, sample_rate = librosa.load(data.loc[0,'Path'], duration=3, offset=0.5,sr=SAMPLE_RATE)\n",
    "signal = np.zeros((int(SAMPLE_RATE*3,)))\n",
    "signal[:len(audio)] = audio\n",
    "mel_spectrogram = getMELspectrogram(signal, SAMPLE_RATE)\n",
    "librosa.display.specshow(mel_spectrogram, y_axis='mel', x_axis='time')\n",
    "print('MEL spectrogram shape: ',mel_spectrogram.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mel_train = []\n",
    "print(\"Calculatin mel spectrograms for train set\")\n",
    "for i in range(X_train.shape[0]):\n",
    "    mel_spectrogram = getMELspectrogram(X_train[i,:], sample_rate=SAMPLE_RATE)\n",
    "    mel_train.append(mel_spectrogram)\n",
    "    print(\"\\r Processed {}/{} files\".format(i,X_train.shape[0]),end='')\n",
    "print('')\n",
    "del X_train\n",
    "\n",
    "mel_val = []\n",
    "print(\"Calculatin mel spectrograms for val set\")\n",
    "for i in range(X_val.shape[0]):\n",
    "    mel_spectrogram = getMELspectrogram(X_val[i,:], sample_rate=SAMPLE_RATE)\n",
    "    mel_val.append(mel_spectrogram)\n",
    "    print(\"\\r Processed {}/{} files\".format(i,X_val.shape[0]),end='')\n",
    "print('')\n",
    "del X_val\n",
    "\n",
    "mel_test = []\n",
    "print(\"Calculatin mel spectrograms for test set\")\n",
    "for i in range(X_test.shape[0]):\n",
    "    mel_spectrogram = getMELspectrogram(X_test[i,:], sample_rate=SAMPLE_RATE)\n",
    "    mel_test.append(mel_spectrogram)\n",
    "    print(\"\\r Processed {}/{} files\".format(i,X_test.shape[0]),end='')\n",
    "print('')\n",
    "del X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = signals\n",
    "train_ind,test_ind,val_ind = [],[],[]\n",
    "X_train,X_val,X_test = [],[],[]\n",
    "Y_train,Y_val,Y_test = [],[],[]\n",
    "# for emotion in range(len(EMOTIONS)):\n",
    "#     emotion_ind = list(data.loc[data.Emotion==emotion,'Emotion'].index)\n",
    "#     emotion_ind = np.random.permutation(emotion_ind)\n",
    "#     m = len(emotion_ind)\n",
    "#     ind_train = emotion_ind[:int(0.8*m)]\n",
    "#     ind_val = emotion_ind[int(0.8*m):int(0.9*m)]\n",
    "#     ind_test = emotion_ind[int(0.9*m):]\n",
    "#     X_train.append(X[ind_train,:])\n",
    "#     Y_train.append(np.array([emotion]*len(ind_train),dtype=np.int32))\n",
    "#     X_val.append(X[ind_val,:])\n",
    "#     Y_val.append(np.array([emotion]*len(ind_val),dtype=np.int32))\n",
    "#     X_test.append(X[ind_test,:])\n",
    "#     Y_test.append(np.array([emotion]*len(ind_test),dtype=np.int32))\n",
    "#     train_ind.append(ind_train)\n",
    "#     test_ind.append(ind_test)\n",
    "#     val_ind.append(ind_val)\n",
    "X_train = np.concatenate(X_train,0)\n",
    "X_val = np.concatenate(X_val,0)\n",
    "X_test = np.concatenate(X_test,0)\n",
    "Y_train = np.concatenate(Y_train,0)\n",
    "Y_val = np.concatenate(Y_val,0)\n",
    "Y_test = np.concatenate(Y_test,0)\n",
    "train_ind = np.concatenate(train_ind,0)\n",
    "val_ind = np.concatenate(val_ind,0)\n",
    "test_ind = np.concatenate(test_ind,0)\n",
    "print(f'X_train:{X_train.shape}, Y_train:{Y_train.shape}')\n",
    "print(f'X_val:{X_val.shape}, Y_val:{Y_val.shape}')\n",
    "print(f'X_test:{X_test.shape}, Y_test:{Y_test.shape}')\n",
    "# check if all are unique\n",
    "unique, count = np.unique(np.concatenate([train_ind,test_ind,val_ind],0), return_counts=True)\n",
    "print(\"Number of unique indexes is {}, out of {}\".format(sum(count==1), X.shape[0]))\n",
    "\n",
    "del X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotPerColumnDistribution(df, nGraphShown, nGraphPerRow):\n",
    "    nunique = df.nunique()\n",
    "    df = df[[col for col in df if nunique[col] > 1 and nunique[col] < 50]] # For displaying purposes, pick columns that have between 1 and 50 unique values\n",
    "    nRow, nCol = df.shape\n",
    "    columnNames = list(df)\n",
    "    nGraphRow = (nCol + nGraphPerRow - 1) / nGraphPerRow\n",
    "    plt.figure(num = None, figsize = (6 * nGraphPerRow, 8 * nGraphRow), dpi = 80, facecolor = 'w', edgecolor = 'k')\n",
    "    for i in range(min(nCol, nGraphShown)):\n",
    "        plt.subplot(nGraphRow, nGraphPerRow, i + 1)\n",
    "        columnDf = df.iloc[:, i]\n",
    "        if (not np.issubdtype(type(columnDf.iloc[0]), np.number)):\n",
    "            valueCounts = columnDf.value_counts()\n",
    "            valueCounts.plot.bar()\n",
    "        else:\n",
    "            columnDf.hist()\n",
    "        plt.ylabel('counts')\n",
    "        plt.xticks(rotation = 90)\n",
    "        plt.title(f'{columnNames[i]} (column {i})')\n",
    "    plt.tight_layout(pad = 1.0, w_pad = 1.0, h_pad = 1.0)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotPerColumnDistribution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.bar(x=range(8), height=data['Emotion'].value_counts())\n",
    "ax.set_xticks(ticks=range(8))\n",
    "ax.set_xticklabels([EMOTIONS[i] for i in range(8)],fontsize=10)\n",
    "ax.set_xlabel('Emotion')\n",
    "ax.set_ylabel('Number of examples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "505a386641657a26778c798b362f0f9b8462f2531dbe2e1d98bc8add872b502f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
